{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "In this homework assignment, you will implement a univariate feature selection method. \n",
    "\n",
    "You will be given a toy dataset called 'Car Evaluation Data Set' (see: http://archive.ics.uci.edu/ml/datasets/Car+Evaluation for details).\n",
    "You are not required to, but advised to test your code with the toy dataset, or any other dataset that contains categorical variables.\n",
    "\n",
    "The given dataset contains six descriptive features and a target variable. Each of those are ordinal scale, categorical variables. The name of the target feature is 'evaluation'. \n",
    "\n",
    "Note here that you are expected to write your own code, so DO NOT COPY AND PASTE CODE OR USE LIBRARY FUNCTIONS. The goal of the homework is not to see if you can call library functions but to have you practice with the impurity measures and feature selection techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying        1728 non-null object\n",
      "maint         1728 non-null object\n",
      "doors         1728 non-null object\n",
      "persons       1728 non-null object\n",
      "lug_boot      1728 non-null object\n",
      "safety        1728 non-null object\n",
      "evaluation    1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "edf = pd.read_csv('careval.csv')\n",
    "# edf.head()\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will create a method called IUFS (impurity-based univariate feature selection), which will select the most informative features with a univariate feature selection schema. This feature selection method will take the dataset, name of the target variable, number of features to be selected (k) and the measure of impurity as an input, and will output the names of k best features based on the information gain. You are expected to implement information gain, entropy and Gini index functions. Note here that this will be a univariate selection, which means that you need to test the features individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy (H)\n",
    "\n",
    "def entropy(feature, dataset):\n",
    "    \"\"\"Calculates the entropy of a feature in a given dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        entropy for the feature in the dataset\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    numrows = float(len(dataset[feature]))\n",
    "    entropy = 0\n",
    "    attribute_counts = dataset[feature].value_counts()\n",
    "    attribute_names = dataset[feature].value_counts().index.tolist()\n",
    "    if sum(attribute_counts) != numrows:\n",
    "        return 'sums do not match up'\n",
    "    elif len(attribute_counts) != len(attribute_names):\n",
    "        return 'something doesnt match up'\n",
    "    for prop in attribute_counts:\n",
    "        p_i = float(prop)/numrows\n",
    "        if p_i != 1:\n",
    "            entropy -= p_i*(math.log(p_i,2))\n",
    "            entropy = round(entropy,4)\n",
    "    return entropy\n",
    "    \n",
    "\n",
    "entropy('buying', edf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gini index (Gini)\n",
    "\n",
    "def gini(feature, dataset):\n",
    "    \"\"\"Calculates the gini index of a feature in a given dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        gini index for the feature in the dataset\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    numrows = float(len(dataset[feature]))\n",
    "    ginival = 1\n",
    "    attribute_counts = dataset[feature].value_counts()\n",
    "    attribute_names = dataset[feature].value_counts().index.tolist()\n",
    "    if sum(attribute_counts) != numrows:\n",
    "        return 'sums do not match up'\n",
    "    elif len(attribute_counts) != len(attribute_names):\n",
    "        return 'something doesnt match up'\n",
    "    for prop in attribute_counts:\n",
    "        p_i = float(prop)/numrows\n",
    "        if p_i != 1:\n",
    "            ginival -= float(p_i*p_i)\n",
    "        else:\n",
    "            ginival = 0\n",
    "        ginival=round(ginival,4)\n",
    "    return ginival\n",
    "  \n",
    "\n",
    "gini('buying', edf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0142"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information gain (IG)\n",
    "\n",
    "def IG(feature, target, dataset, measure):\n",
    "    \"\"\"Calculates the information gain of a feature for a given target variable and a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    measure: str ('entropy' or 'gini')\n",
    "        measure of impurity to be used\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        information gain for the feature in the dataset for a given target variable\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "\n",
    "    cols = []\n",
    "    for col in dataset.columns:\n",
    "        if col != target:\n",
    "            cols.append(col)\n",
    "    if feature not in cols:\n",
    "        return 'the feature to be split on is not in the feature set'\n",
    "    attribute_counts = dataset[feature].value_counts()\n",
    "    attribute_names = dataset[feature].value_counts().index.tolist()\n",
    "    numrows = float(len(dataset[feature]))\n",
    "    \n",
    "    if(measure=='entropy'):\n",
    "     value1 = entropy(target,dataset)\n",
    "     for i in range(len(attribute_names)):\n",
    "        df = dataset.loc[dataset[feature] == attribute_names[i]]\n",
    "        part = entropy(target,df)\n",
    "        part = part * (float(df.shape[0])/numrows)\n",
    "        part = round(part,4)\n",
    "        value1 -= part\n",
    "        value1=round(value1,4)   \n",
    "        \n",
    "    elif(measure=='gini'):\n",
    "     value1 = gini(target,dataset)\n",
    "     value1 = round(value1,4)\n",
    "     for i in range(len(attribute_names)):\n",
    "        df = dataset.loc[dataset[feature] == attribute_names[i]]\n",
    "        part = gini(target,df)\n",
    "        part = round(part,4)\n",
    "        part = part * (float(df.shape[0])/numrows)\n",
    "        value1 -= part\n",
    "        value1=round(value1,4)\n",
    "    return value1\n",
    "    pass\n",
    "\n",
    "\n",
    "IG('buying','evaluation', edf, 'gini') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     safety\n",
       "3    persons\n",
       "Name: Attributes, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IUFS(target, dataset, k, measure='entropy'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    attributes = []\n",
    "    IGval = []\n",
    "    if((k<len(dataset.columns))&(k>0)):\n",
    "        for col in dataset.columns:\n",
    "            if col != target:\n",
    "                attributes.append(col)\n",
    "                IGval.append(IG(col,target,dataset,measure))\n",
    "                list_of_tuples = list(zip(attributes, IGval))\n",
    "                list_of_tuples\n",
    "                df = pd.DataFrame(list_of_tuples, columns = ['Attributes', 'Information Gain']) \n",
    "                df.sort_values(\"Information Gain\", axis = 0, ascending = False, \n",
    "                 inplace = True)\n",
    "                selectedFeatures=pd.Series()\n",
    "                selectedFeatures=df['Attributes'].head(k)\n",
    "    else:\n",
    "        selectedFeatures=\"Update the count of attributes\"\n",
    "    return selectedFeatures\n",
    "    \n",
    "IUFS('evaluation', edf, 2, measure='entropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Improve the IUFS by including an option for gain ratio. Gain ratio is an alternative to information gain and can be used with either of the Gini index or entropy measures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018933333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GR(feature, target, dataset, measure):\n",
    "    \"\"\"Calculates the gain ratio of a feature for a given target variable and a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    measure: str ('entropy' or 'gini')\n",
    "        measure of impurity to be used\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        gain ratio for the feature in the dataset for a given target variable\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    IGval=IG(feature, target, dataset, measure) \n",
    "    if(measure=='entropy'):\n",
    "        entropyval=entropy(feature,dataset)\n",
    "        gainratio=IGval/entropyval\n",
    "    elif(measure=='gini'):\n",
    "        ginival=gini(feature,dataset)\n",
    "        gainratio=IGval/ginival\n",
    "    return gainratio\n",
    "  \n",
    "GR('buying','evaluation', edf, 'gini') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     safety\n",
       "3    persons\n",
       "Name: Attributes, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IUFS2(target, dataset, k, measure='entropy', gain='IG'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    gain: str, 'IG' or 'GR'\n",
    "        feature selection metric ('IG' for information gain, 'GR' for gain ratio)\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    attributes = []\n",
    "    IGval = []\n",
    "    GRatio = []\n",
    "    if((k<len(dataset.columns))&(k>0)):\n",
    "        for col in dataset.columns:\n",
    "            if col != target:\n",
    "                attributes.append(col)\n",
    "                if(gain=='GR'):\n",
    "                    GRatio.append(GR(col,target,dataset,measure))   \n",
    "                    list_of_tuples = list(zip(attributes, GRatio))\n",
    "                    list_of_tuples\n",
    "                    df = pd.DataFrame(list_of_tuples, columns = ['Attributes', 'Gain Ratio']) \n",
    "                    df.sort_values(\"Gain Ratio\", axis = 0, ascending = False, inplace = True)\n",
    "                    selectedFeatures=pd.Series()\n",
    "                    selectedFeatures=df['Attributes'].head(k)\n",
    "                elif(gain=='IG'):\n",
    "                    IGval.append(IG(col,target,dataset,measure))\n",
    "                    list_of_tuples = list(zip(attributes, IGval))\n",
    "                    list_of_tuples\n",
    "                    df = pd.DataFrame(list_of_tuples, columns = ['Attributes', 'Information Gain']) \n",
    "                    df.sort_values(\"Information Gain\", axis = 0, ascending = False, inplace = True)\n",
    "                    selectedFeatures=pd.Series()\n",
    "                    selectedFeatures=df['Attributes'].head(k)\n",
    "    else:\n",
    "        selectedFeatures=\"Update the count of attributes\"\n",
    "    return selectedFeatures\n",
    "\n",
    "IUFS2('evaluation', edf, 2, measure='gini', gain='GR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
